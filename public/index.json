[
  {
    "id": 0,
    "title": "First Post",
    "content": "Why Should I write this This is my first post. Testing the blog setup.\nWhat to expect More content coming soon about marketing analytics and experimentation.\n",
    "tags": ["testing","intro"],
    "date": "2025-10-16",
    "permalink": "http://localhost:1313/posts/first-post/",
    "summary": "Why Should I write this This is my first post. Testing the blog setup.\nWhat to expect More content coming soon about marketing analytics and experimentation.\n"
  },
  {
    "id": 1,
    "title": "A/B Testing Simulator",
    "content": "A/B Testing Simulator Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.\nSection 1: Your Variant Your Assigned Variant You are in: Loading...\nLoading\u0026hellip;\nSection 2: Live Dashboard Results (Live) Variant A Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nVariant B Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nStatistical Significance p-value: -\nProb(B \u003e A): -\nLast updated: never\nSection 3: Python Code How We Calculate It This is the actual Python code powering the analysis:\nimport pandas as pd from scipy import stats as scipy_stats import numpy as np # Load experiment data df = pd.read_csv('events.csv') # Split by variant a = df[df['variant'] == 'A']['converted'] b = df[df['variant'] == 'B']['converted'] # Frequentist: Chi-square test contingency = [[a.sum(), len(a)-a.sum()], [b.sum(), len(b)-b.sum()]] chi2, p_value, dof, expected = scipy_stats.chi2_contingency(contingency) # Bayesian: Beta-Binomial credible intervals alpha, beta = 1, 1 # Uniform priors a_alpha = alpha + a.sum() a_beta = beta + (len(a) - a.sum()) a_ci = scipy_stats.beta.ppf([0.025, 0.975], a_alpha, a_beta) Section 4: Education Understanding the Results Why Bayesian and Frequentist? This simulator shows both approaches because they answer different questions:\nFrequentist: \"If we repeated this experiment many times, how often would we see this difference by chance?\" Bayesian: \"Given what we've observed, what's the probability that B is actually better than A?\" What Are Credible Intervals? The 95% credible interval [10%, 14%] means: \"We're 95% confident the true conversion rate is between 10% and 14%.\"\nWhat Does p-value Mean? A p-value of 0.047 means: \"There's a 4.7% chance we'd see this difference if both variants were actually the same.\"\nCommon Mistakes ❌ Peeking at results before reaching target sample size ❌ Stopping early because one variant is winning ❌ Running multiple tests without correcting for them ✅ Planning sample size before the test ✅ Running tests for the full planned duration ",
    "tags": null,
    "date": "2025-10-17",
    "permalink": "http://localhost:1313/experiments/ab-test-simulator/",
    "summary": "A/B Testing Simulator Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.\nSection 1: Your Variant Your Assigned Variant You are in: Loading...\nLoading\u0026hellip;\nSection 2: Live Dashboard Results (Live) Variant A Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nVariant B Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nStatistical Significance p-value: -\nProb(B \u003e A): -\nLast updated: never\nSection 3: Python Code How We Calculate It This is the actual Python code powering the analysis:\n"
  }]