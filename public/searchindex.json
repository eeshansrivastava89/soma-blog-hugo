[{"content":"Why Should I write this This is my first post. Testing the blog setup.\nWhat to expect More content coming soon about marketing analytics and experimentation.\n","date":"October 16, 2025","id":0,"permalink":"/posts/first-post/","summary":"This is my first post. Testing the blog setup.","tags":"testing intro","title":"First Post"},{"content":"Why Should I write this This is my first post. Testing the blog setup.\nWhat to expect More content coming soon about marketing analytics and experimentation.\n","date":"October 16, 2025","id":0,"permalink":"/posts/first-post/","summary":"This is my first post. Testing the blog setup.","tags":"testing intro","title":"First Post"},{"content":"A/B Testing Simulator Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.\nSection 1: Your Variant Your Assigned Variant You are in: Loading...\nLoading\u0026hellip;\nSection 2: Live Dashboard Results (Live) Variant A Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\n\u0026lt;div class=\u0026quot;variant-stats\u0026quot;\u0026gt; \u0026lt;h4\u0026gt;Variant B\u0026lt;/h4\u0026gt; \u0026lt;p\u0026gt;Users: \u0026lt;strong id=\u0026quot;variant-b-users\u0026quot;\u0026gt;0\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Conversions: \u0026lt;strong id=\u0026quot;variant-b-conversions\u0026quot;\u0026gt;0\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Rate: \u0026lt;strong id=\u0026quot;variant-b-rate\u0026quot;\u0026gt;0%\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;95% CI: \u0026lt;strong id=\u0026quot;variant-b-ci\u0026quot;\u0026gt;[-, -]\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; Statistical Significance p-value: -\nProb(B \u003e A): -\nLast updated: never\nSection 3: Python Code How We Calculate It This is the actual Python code powering the analysis:\nimport pandas as pd from scipy import stats as scipy_stats import numpy as np # Load experiment data df = pd.read_csv('events.csv') # Split by variant a = df[df['variant'] == 'A']['converted'] b = df[df['variant'] == 'B']['converted'] # Frequentist: Chi-square test contingency = [[a.sum(), len(a)-a.sum()], [b.sum(), len(b)-b.sum()]] chi2, p_value, dof, expected = scipy_stats.chi2_contingency(contingency) # Bayesian: Beta-Binomial credible intervals alpha, beta = 1, 1 # Uniform priors a_alpha = alpha + a.sum() a_beta = beta + (len(a) - a.sum()) a_ci = scipy_stats.beta.ppf([0.025, 0.975], a_alpha, a_beta) Section 4: Education Understanding the Results Why Bayesian and Frequentist? This simulator shows both approaches because they answer different questions:\nFrequentist: \"If we repeated this experiment many times, how often would we see this difference by chance?\" Bayesian: \"Given what we've observed, what's the probability that B is actually better than A?\" What Are Credible Intervals? The 95% credible interval [10%, 14%] means: \"We're 95% confident the true conversion rate is between 10% and 14%.\"\nWhat Does p-value Mean? A p-value of 0.047 means: \"There's a 4.7% chance we'd see this difference if both variants were actually the same.\"\nCommon Mistakes ❌ Peeking at results before reaching target sample size ❌ Stopping early because one variant is winning ❌ Running multiple tests without correcting for them ✅ Planning sample size before the test ✅ Running tests for the full planned duration ","date":"October 17, 2025","id":1,"permalink":"/experiments/ab-test-simulator/","summary":"Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.","tags":"","title":"A/B Testing Simulator"},{"content":"Why Should I write this This is my first post. Testing the blog setup.\nWhat to expect More content coming soon about marketing analytics and experimentation.\n","date":"October 16, 2025","id":0,"permalink":"/posts/first-post/","summary":"This is my first post. Testing the blog setup.","tags":"testing intro","title":"First Post"},{"content":"A/B Testing Simulator Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.\nSection 1: Your Variant Your Assigned Variant You are in: Loading...\nLoading\u0026hellip;\nSection 2: Live Dashboard Results (Live) Variant A Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nVariant B Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nStatistical Significance p-value: -\nProb(B \u003e A): -\nLast updated: never\nSection 3: Python Code How We Calculate It This is the actual Python code powering the analysis:\nimport pandas as pd from scipy import stats as scipy_stats import numpy as np # Load experiment data df = pd.read_csv('events.csv') # Split by variant a = df[df['variant'] == 'A']['converted'] b = df[df['variant'] == 'B']['converted'] # Frequentist: Chi-square test contingency = [[a.sum(), len(a)-a.sum()], [b.sum(), len(b)-b.sum()]] chi2, p_value, dof, expected = scipy_stats.chi2_contingency(contingency) # Bayesian: Beta-Binomial credible intervals alpha, beta = 1, 1 # Uniform priors a_alpha = alpha + a.sum() a_beta = beta + (len(a) - a.sum()) a_ci = scipy_stats.beta.ppf([0.025, 0.975], a_alpha, a_beta) Section 4: Education Understanding the Results Why Bayesian and Frequentist? This simulator shows both approaches because they answer different questions:\nFrequentist: \"If we repeated this experiment many times, how often would we see this difference by chance?\" Bayesian: \"Given what we've observed, what's the probability that B is actually better than A?\" What Are Credible Intervals? The 95% credible interval [10%, 14%] means: \"We're 95% confident the true conversion rate is between 10% and 14%.\"\nWhat Does p-value Mean? A p-value of 0.047 means: \"There's a 4.7% chance we'd see this difference if both variants were actually the same.\"\nCommon Mistakes ❌ Peeking at results before reaching target sample size ❌ Stopping early because one variant is winning ❌ Running multiple tests without correcting for them ✅ Planning sample size before the test ✅ Running tests for the full planned duration ","date":"October 17, 2025","id":1,"permalink":"/experiments/ab-test-simulator/","summary":"Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.","tags":"","title":"A/B Testing Simulator"},{"content":"Why Should I write this This is my first post. Testing the blog setup.\nWhat to expect More content coming soon about marketing analytics and experimentation.\n","date":"October 16, 2025","id":0,"permalink":"/posts/first-post/","summary":"This is my first post. Testing the blog setup.","tags":"testing intro","title":"First Post"},{"content":"A/B Testing Simulator Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.\nSection 1: Your Variant Your Assigned Variant You are in: Loading...\nLoading\u0026hellip;\nSection 2: Live Dashboard Results (Live) Variant A Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nVariant B Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nStatistical Significance p-value: -\nProb(B \u003e A): -\nLast updated: never\nSection 3: Python Code How We Calculate It This is the actual Python code powering the analysis:\nimport pandas as pd from scipy import stats as scipy_stats import numpy as np # Load experiment data df = pd.read_csv('events.csv') # Split by variant a = df[df['variant'] == 'A']['converted'] b = df[df['variant'] == 'B']['converted'] # Frequentist: Chi-square test contingency = [[a.sum(), len(a)-a.sum()], [b.sum(), len(b)-b.sum()]] chi2, p_value, dof, expected = scipy_stats.chi2_contingency(contingency) # Bayesian: Beta-Binomial credible intervals alpha, beta = 1, 1 # Uniform priors a_alpha = alpha + a.sum() a_beta = beta + (len(a) - a.sum()) a_ci = scipy_stats.beta.ppf([0.025, 0.975], a_alpha, a_beta) Section 4: Education Understanding the Results Why Bayesian and Frequentist? This simulator shows both approaches because they answer different questions:\nFrequentist: \"If we repeated this experiment many times, how often would we see this difference by chance?\" Bayesian: \"Given what we've observed, what's the probability that B is actually better than A?\" What Are Credible Intervals? The 95% credible interval [10%, 14%] means: \"We're 95% confident the true conversion rate is between 10% and 14%.\"\nWhat Does p-value Mean? A p-value of 0.047 means: \"There's a 4.7% chance we'd see this difference if both variants were actually the same.\"\nCommon Mistakes ❌ Peeking at results before reaching target sample size ❌ Stopping early because one variant is winning ❌ Running multiple tests without correcting for them ✅ Planning sample size before the test ✅ Running tests for the full planned duration ","date":"October 17, 2025","id":1,"permalink":"/experiments/ab-test-simulator/","summary":"Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.","tags":"","title":"A/B Testing Simulator"},{"content":"Why Should I write this This is my first post. Testing the blog setup.\nWhat to expect More content coming soon about marketing analytics and experimentation.\n","date":"October 16, 2025","id":0,"permalink":"/posts/first-post/","summary":"This is my first post. Testing the blog setup.","tags":"testing intro","title":"First Post"},{"content":"A/B Testing Simulator Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.\nSection 1: Your Variant Your Assigned Variant You are in: Loading...\nLoading\u0026hellip;\nSection 2: Live Dashboard Results (Live) Variant A Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nVariant B Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nStatistical Significance p-value: -\nProb(B \u003e A): -\nLast updated: never\nSection 3: Python Code How We Calculate It This is the actual Python code powering the analysis:\nimport pandas as pd from scipy import stats as scipy_stats import numpy as np # Load experiment data df = pd.read_csv('events.csv') # Split by variant a = df[df['variant'] == 'A']['converted'] b = df[df['variant'] == 'B']['converted'] # Frequentist: Chi-square test contingency = [[a.sum(), len(a)-a.sum()], [b.sum(), len(b)-b.sum()]] chi2, p_value, dof, expected = scipy_stats.chi2_contingency(contingency) # Bayesian: Beta-Binomial credible intervals alpha, beta = 1, 1 # Uniform priors a_alpha = alpha + a.sum() a_beta = beta + (len(a) - a.sum()) a_ci = scipy_stats.beta.ppf([0.025, 0.975], a_alpha, a_beta) Section 4: Education Understanding the Results Why Bayesian and Frequentist? This simulator shows both approaches because they answer different questions:\nFrequentist: \"If we repeated this experiment many times, how often would we see this difference by chance?\" Bayesian: \"Given what we've observed, what's the probability that B is actually better than A?\" What Are Credible Intervals? The 95% credible interval [10%, 14%] means: \"We're 95% confident the true conversion rate is between 10% and 14%.\"\nWhat Does p-value Mean? A p-value of 0.047 means: \"There's a 4.7% chance we'd see this difference if both variants were actually the same.\"\nCommon Mistakes ❌ Peeking at results before reaching target sample size ❌ Stopping early because one variant is winning ❌ Running multiple tests without correcting for them ✅ Planning sample size before the test ✅ Running tests for the full planned duration ","date":"October 17, 2025","id":1,"permalink":"/experiments/ab-test-simulator/","summary":"Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.","tags":"","title":"A/B Testing Simulator"},{"content":"Why Should I write this This is my first post. Testing the blog setup.\nWhat to expect More content coming soon about marketing analytics and experimentation.\n","date":"October 16, 2025","id":0,"permalink":"/posts/first-post/","summary":"This is my first post. Testing the blog setup.","tags":"testing intro","title":"First Post"},{"content":"A/B Testing Simulator Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.\nSection 1: Your Variant Your Assigned Variant You are in: Loading...\nLoading\u0026hellip;\nSection 2: Live Dashboard Results (Live) Variant A Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nVariant B Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nStatistical Significance p-value: -\nProb(B \u003e A): -\nLast updated: never\nSection 3: Python Code How We Calculate It This is the actual Python code powering the analysis:\nimport pandas as pd from scipy import stats as scipy_stats import numpy as np # Load experiment data df = pd.read_csv('events.csv') # Split by variant a = df[df['variant'] == 'A']['converted'] b = df[df['variant'] == 'B']['converted'] # Frequentist: Chi-square test contingency = [[a.sum(), len(a)-a.sum()], [b.sum(), len(b)-b.sum()]] chi2, p_value, dof, expected = scipy_stats.chi2_contingency(contingency) # Bayesian: Beta-Binomial credible intervals alpha, beta = 1, 1 # Uniform priors a_alpha = alpha + a.sum() a_beta = beta + (len(a) - a.sum()) a_ci = scipy_stats.beta.ppf([0.025, 0.975], a_alpha, a_beta) Section 4: Education Understanding the Results Why Bayesian and Frequentist? This simulator shows both approaches because they answer different questions:\nFrequentist: \"If we repeated this experiment many times, how often would we see this difference by chance?\" Bayesian: \"Given what we've observed, what's the probability that B is actually better than A?\" What Are Credible Intervals? The 95% credible interval [10%, 14%] means: \"We're 95% confident the true conversion rate is between 10% and 14%.\"\nWhat Does p-value Mean? A p-value of 0.047 means: \"There's a 4.7% chance we'd see this difference if both variants were actually the same.\"\nCommon Mistakes ❌ Peeking at results before reaching target sample size ❌ Stopping early because one variant is winning ❌ Running multiple tests without correcting for them ✅ Planning sample size before the test ✅ Running tests for the full planned duration ","date":"October 17, 2025","id":1,"permalink":"/experiments/ab-test-simulator/","summary":"Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.","tags":"","title":"A/B Testing Simulator"},{"content":"Why Should I write this This is my first post. Testing the blog setup.\nWhat to expect More content coming soon about marketing analytics and experimentation.\n","date":"October 16, 2025","id":0,"permalink":"/posts/first-post/","summary":"This is my first post. Testing the blog setup.","tags":"testing intro","title":"First Post"},{"content":"A/B Testing Simulator Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.\nSection 1: Your Variant Your Assigned Variant You are in: Loading...\nLoading\u0026hellip;\nSection 2: Live Dashboard Results (Live) Variant A Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nVariant B Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nStatistical Significance p-value: -\nProb(B \u003e A): -\nLast updated: never\nSection 3: Python Code How We Calculate It This is the actual Python code powering the analysis:\nimport pandas as pd from scipy import stats as scipy_stats import numpy as np # Load experiment data df = pd.read_csv('events.csv') # Split by variant a = df[df['variant'] == 'A']['converted'] b = df[df['variant'] == 'B']['converted'] # Frequentist: Chi-square test contingency = [[a.sum(), len(a)-a.sum()], [b.sum(), len(b)-b.sum()]] chi2, p_value, dof, expected = scipy_stats.chi2_contingency(contingency) # Bayesian: Beta-Binomial credible intervals alpha, beta = 1, 1 # Uniform priors a_alpha = alpha + a.sum() a_beta = beta + (len(a) - a.sum()) a_ci = scipy_stats.beta.ppf([0.025, 0.975], a_alpha, a_beta) Section 4: Education Understanding the Results Why Bayesian and Frequentist? This simulator shows both approaches because they answer different questions:\nFrequentist: \"If we repeated this experiment many times, how often would we see this difference by chance?\" Bayesian: \"Given what we've observed, what's the probability that B is actually better than A?\" What Are Credible Intervals? The 95% credible interval [10%, 14%] means: \"We're 95% confident the true conversion rate is between 10% and 14%.\"\nWhat Does p-value Mean? A p-value of 0.047 means: \"There's a 4.7% chance we'd see this difference if both variants were actually the same.\"\nCommon Mistakes ❌ Peeking at results before reaching target sample size ❌ Stopping early because one variant is winning ❌ Running multiple tests without correcting for them ✅ Planning sample size before the test ✅ Running tests for the full planned duration ","date":"October 17, 2025","id":1,"permalink":"/experiments/ab-test-simulator/","summary":"Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.","tags":"","title":"A/B Testing Simulator"},{"content":"Why Should I write this This is my first post. Testing the blog setup.\nWhat to expect More content coming soon about marketing analytics and experimentation.\n","date":"October 16, 2025","id":0,"permalink":"/posts/first-post/","summary":"This is my first post. Testing the blog setup.","tags":"testing intro","title":"First Post"},{"content":"A/B Testing Simulator Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.\nSection 1: Your Variant Your Assigned Variant You are in: Loading...\nLoading\u0026hellip;\nSection 2: Live Dashboard Results (Live) Variant A Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nVariant B Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nStatistical Significance p-value: -\nProb(B \u003e A): -\nLast updated: never\nSection 3: Python Code How We Calculate It This is the actual Python code powering the analysis:\nimport pandas as pd from scipy import stats as scipy_stats import numpy as np # Load experiment data df = pd.read_csv('events.csv') # Split by variant a = df[df['variant'] == 'A']['converted'] b = df[df['variant'] == 'B']['converted'] # Frequentist: Chi-square test contingency = [[a.sum(), len(a)-a.sum()], [b.sum(), len(b)-b.sum()]] chi2, p_value, dof, expected = scipy_stats.chi2_contingency(contingency) # Bayesian: Beta-Binomial credible intervals alpha, beta = 1, 1 # Uniform priors a_alpha = alpha + a.sum() a_beta = beta + (len(a) - a.sum()) a_ci = scipy_stats.beta.ppf([0.025, 0.975], a_alpha, a_beta) Section 4: Education Understanding the Results Why Bayesian and Frequentist? This simulator shows both approaches because they answer different questions:\nFrequentist: \"If we repeated this experiment many times, how often would we see this difference by chance?\" Bayesian: \"Given what we've observed, what's the probability that B is actually better than A?\" What Are Credible Intervals? The 95% credible interval [10%, 14%] means: \"We're 95% confident the true conversion rate is between 10% and 14%.\"\nWhat Does p-value Mean? A p-value of 0.047 means: \"There's a 4.7% chance we'd see this difference if both variants were actually the same.\"\nCommon Mistakes ❌ Peeking at results before reaching target sample size ❌ Stopping early because one variant is winning ❌ Running multiple tests without correcting for them ✅ Planning sample size before the test ✅ Running tests for the full planned duration ","date":"October 17, 2025","id":1,"permalink":"/experiments/ab-test-simulator/","summary":"Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.","tags":"","title":"A/B Testing Simulator"},{"content":"Why Should I write this This is my first post. Testing the blog setup.\nWhat to expect More content coming soon about marketing analytics and experimentation.\n","date":"October 16, 2025","id":0,"permalink":"/posts/first-post/","summary":"This is my first post. Testing the blog setup.","tags":"testing intro","title":"First Post"},{"content":"A/B Testing Simulator Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.\nSection 1: Your Variant Your Assigned Variant You are in: Loading...\nLoading\u0026hellip;\nSection 2: Live Dashboard Results (Live) Variant A Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nVariant B Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nStatistical Significance p-value: -\nProb(B \u003e A): -\nLast updated: never\nSection 3: Python Code How We Calculate It This is the actual Python code powering the analysis:\nimport pandas as pd from scipy import stats as scipy_stats import numpy as np # Load experiment data df = pd.read_csv('events.csv') # Split by variant a = df[df['variant'] == 'A']['converted'] b = df[df['variant'] == 'B']['converted'] # Frequentist: Chi-square test contingency = [[a.sum(), len(a)-a.sum()], [b.sum(), len(b)-b.sum()]] chi2, p_value, dof, expected = scipy_stats.chi2_contingency(contingency) # Bayesian: Beta-Binomial credible intervals alpha, beta = 1, 1 # Uniform priors a_alpha = alpha + a.sum() a_beta = beta + (len(a) - a.sum()) a_ci = scipy_stats.beta.ppf([0.025, 0.975], a_alpha, a_beta) Section 4: Education Understanding the Results Why Bayesian and Frequentist? This simulator shows both approaches because they answer different questions:\nFrequentist: \"If we repeated this experiment many times, how often would we see this difference by chance?\" Bayesian: \"Given what we've observed, what's the probability that B is actually better than A?\" What Are Credible Intervals? The 95% credible interval [10%, 14%] means: \"We're 95% confident the true conversion rate is between 10% and 14%.\"\nWhat Does p-value Mean? A p-value of 0.047 means: \"There's a 4.7% chance we'd see this difference if both variants were actually the same.\"\nCommon Mistakes ❌ Peeking at results before reaching target sample size ❌ Stopping early because one variant is winning ❌ Running multiple tests without correcting for them ✅ Planning sample size before the test ✅ Running tests for the full planned duration ","date":"October 17, 2025","id":1,"permalink":"/experiments/ab-test-simulator/","summary":"Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.","tags":"","title":"A/B Testing Simulator"},{"content":"Why Should I write this This is my first post. Testing the blog setup.\nWhat to expect More content coming soon about marketing analytics and experimentation.\n","date":"October 16, 2025","id":0,"permalink":"/posts/first-post/","summary":"This is my first post. Testing the blog setup.","tags":"testing intro","title":"First Post"},{"content":"Why Should I write this This is my first post. Testing the blog setup.\nWhat to expect More content coming soon about marketing analytics and experimentation.\n","date":"October 16, 2025","id":0,"permalink":"/posts/first-post/","summary":"This is my first post. Testing the blog setup.","tags":"testing intro","title":"First Post"},{"content":"A/B Testing Simulator Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.\nSection 1: Your Variant Your Assigned Variant You are in: Loading...\nLoading\u0026hellip;\nSection 2: Live Dashboard Results (Live) Variant A Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nVariant B Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nStatistical Significance p-value: -\nProb(B \u003e A): -\nLast updated: never\nSection 3: Python Code How We Calculate It This is the actual Python code powering the analysis:\nimport pandas as pd from scipy import stats as scipy_stats import numpy as np # Load experiment data df = pd.read_csv('events.csv') # Split by variant a = df[df['variant'] == 'A']['converted'] b = df[df['variant'] == 'B']['converted'] # Frequentist: Chi-square test contingency = [[a.sum(), len(a)-a.sum()], [b.sum(), len(b)-b.sum()]] chi2, p_value, dof, expected = scipy_stats.chi2_contingency(contingency) # Bayesian: Beta-Binomial credible intervals alpha, beta = 1, 1 # Uniform priors a_alpha = alpha + a.sum() a_beta = beta + (len(a) - a.sum()) a_ci = scipy_stats.beta.ppf([0.025, 0.975], a_alpha, a_beta) Section 4: Education Understanding the Results Why Bayesian and Frequentist? This simulator shows both approaches because they answer different questions:\nFrequentist: \"If we repeated this experiment many times, how often would we see this difference by chance?\" Bayesian: \"Given what we've observed, what's the probability that B is actually better than A?\" What Are Credible Intervals? The 95% credible interval [10%, 14%] means: \"We're 95% confident the true conversion rate is between 10% and 14%.\"\nWhat Does p-value Mean? A p-value of 0.047 means: \"There's a 4.7% chance we'd see this difference if both variants were actually the same.\"\nCommon Mistakes ❌ Peeking at results before reaching target sample size ❌ Stopping early because one variant is winning ❌ Running multiple tests without correcting for them ✅ Planning sample size before the test ✅ Running tests for the full planned duration ","date":"October 17, 2025","id":1,"permalink":"/experiments/ab-test-simulator/","summary":"Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.","tags":"","title":"A/B Testing Simulator"},{"content":"Why Should I write this This is my first post. Testing the blog setup.\nWhat to expect More content coming soon about marketing analytics and experimentation.\n","date":"October 16, 2025","id":0,"permalink":"/posts/first-post/","summary":"This is my first post. Testing the blog setup.","tags":"testing intro","title":"First Post"},{"content":"A/B Testing Simulator Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.\nSection 1: Your Variant Your Assigned Variant You are in: Loading...\nLoading\u0026hellip;\nSection 2: Live Dashboard Results (Live) Variant A Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nVariant B Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nStatistical Significance p-value: -\nProb(B \u003e A): -\nLast updated: never\nSection 3: Python Code How We Calculate It This is the actual Python code powering the analysis:\nimport pandas as pd from scipy import stats as scipy_stats import numpy as np # Load experiment data df = pd.read_csv('events.csv') # Split by variant a = df[df['variant'] == 'A']['converted'] b = df[df['variant'] == 'B']['converted'] # Frequentist: Chi-square test contingency = [[a.sum(), len(a)-a.sum()], [b.sum(), len(b)-b.sum()]] chi2, p_value, dof, expected = scipy_stats.chi2_contingency(contingency) # Bayesian: Beta-Binomial credible intervals alpha, beta = 1, 1 # Uniform priors a_alpha = alpha + a.sum() a_beta = beta + (len(a) - a.sum()) a_ci = scipy_stats.beta.ppf([0.025, 0.975], a_alpha, a_beta) Section 4: Education Understanding the Results Why Bayesian and Frequentist? This simulator shows both approaches because they answer different questions:\nFrequentist: \"If we repeated this experiment many times, how often would we see this difference by chance?\" Bayesian: \"Given what we've observed, what's the probability that B is actually better than A?\" What Are Credible Intervals? The 95% credible interval [10%, 14%] means: \"We're 95% confident the true conversion rate is between 10% and 14%.\"\nWhat Does p-value Mean? A p-value of 0.047 means: \"There's a 4.7% chance we'd see this difference if both variants were actually the same.\"\nCommon Mistakes ❌ Peeking at results before reaching target sample size ❌ Stopping early because one variant is winning ❌ Running multiple tests without correcting for them ✅ Planning sample size before the test ✅ Running tests for the full planned duration ","date":"October 17, 2025","id":1,"permalink":"/experiments/ab-test-simulator/","summary":"Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.","tags":"","title":"A/B Testing Simulator"},{"content":"Why Should I write this This is my first post. Testing the blog setup.\nWhat to expect More content coming soon about marketing analytics and experimentation.\n","date":"October 16, 2025","id":0,"permalink":"/posts/first-post/","summary":"This is my first post. Testing the blog setup.","tags":"testing intro","title":"First Post"},{"content":"A/B Testing Simulator Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.\nSection 1: Your Variant Your Assigned Variant You are in: Loading...\nLoading\u0026hellip;\nSection 2: Live Dashboard Results (Live) Variant A Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nVariant B Users: 0\nConversions: 0\nRate: 0%\n95% CI: [-, -]\nStatistical Significance p-value: -\nProb(B \u003e A): -\nLast updated: never\nSection 3: Python Code How We Calculate It This is the actual Python code powering the analysis:\nimport pandas as pd from scipy import stats as scipy_stats import numpy as np # Load experiment data df = pd.read_csv('events.csv') # Split by variant a = df[df['variant'] == 'A']['converted'] b = df[df['variant'] == 'B']['converted'] # Frequentist: Chi-square test contingency = [[a.sum(), len(a)-a.sum()], [b.sum(), len(b)-b.sum()]] chi2, p_value, dof, expected = scipy_stats.chi2_contingency(contingency) # Bayesian: Beta-Binomial credible intervals alpha, beta = 1, 1 # Uniform priors a_alpha = alpha + a.sum() a_beta = beta + (len(a) - a.sum()) a_ci = scipy_stats.beta.ppf([0.025, 0.975], a_alpha, a_beta) Section 4: Education Understanding the Results Why Bayesian and Frequentist? This simulator shows both approaches because they answer different questions:\nFrequentist: \"If we repeated this experiment many times, how often would we see this difference by chance?\" Bayesian: \"Given what we've observed, what's the probability that B is actually better than A?\" What Are Credible Intervals? The 95% credible interval [10%, 14%] means: \"We're 95% confident the true conversion rate is between 10% and 14%.\"\nWhat Does p-value Mean? A p-value of 0.047 means: \"There's a 4.7% chance we'd see this difference if both variants were actually the same.\"\nCommon Mistakes ❌ Peeking at results before reaching target sample size ❌ Stopping early because one variant is winning ❌ Running multiple tests without correcting for them ✅ Planning sample size before the test ✅ Running tests for the full planned duration ","date":"October 17, 2025","id":1,"permalink":"/experiments/ab-test-simulator/","summary":"Welcome! This is an interactive simulator where you can see A/B testing and statistical analysis in action.","tags":"","title":"A/B Testing Simulator"}]